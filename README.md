# toxic_finder
model for classifying comment. toxic(1)/or not(1)
